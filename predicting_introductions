###just need the machine learning to identify when a person is talking or not. Speech recognition will pick the names out###


# The path to the directory where the original

# dataset was uncompressed

original_dataset_dir = '' #need a dataset

# The directory where we will

# store our smaller dataset

base_dir = '' #need to crete a place to store dataset

os.mkdir(base_dir)



from keras.models import load_model

model = load_model('ppl_introducing_themselves,ppl_talking,ppl_not_talking_with_added_background_talking')



###all below need to be changed to support the video stream and not just image files###

img_path = 'codec'

# We preprocess the codec into a 4D tensor

from keras.preprocessing import codec

import numpy as np

codec = #import video feed

img_tensor = image.img_to_array(img)

img_tensor = np.expand_dims(img_tensor, axis=0)

# Remember that the model was trained on inputs

# that were preprocessed in the following way:

img_tensor /= 255.

# Its shape is (1, 150, 150, 3)

print(img_tensor.shape)



import matplotlib.pyplot as plt

plt.imshow(img_tensor[0]) ### change to video ###

plt.show()



prediction = model.predict(img_tensor)

print(prediction)

[[ ]] ##not sure what this number should be##
