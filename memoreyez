#!/bin/bash



memoreyez_APP_FOLDER=$(cd `dirname $0`/../; pwd)

memoreyez_APP_ORG=com.github.pion

MEMOREYEZ_APP_PROJECT_NAME=ion_sfu_example

CMD=$1


 cleanup() {

    echo "Cleanup project [$MEMOREYEZ_APP_PROJECT_NAME] files ..."

    cd $MEMOREYEZ_APP_FOLDER

    rm -rf android build *.iml ios pubspec.lock test .??????-plugins .metadata .packages .idea

}



 create() {

    cd $MEMOREYEZ_APP_FOLDER

     [ ! -d "ios" ] && [ ! -d "android" ];then

        echo "Create Memoreyez project: name=$MEMOREYEZ_APP_PROJECT_NAME, org=$MEMOREYEZ_APP_ORG ..."

        flutter create --project-name $MEMOREYEZ_APP_PROJECT_NAME --org $MEMOREYEZ_APP_ORG .

        add_permission_label

    

        echo "Project [$MEMOREYEZ_APP_PROJECT_NAME] already exists!"

    

}



 add_permission_label() {

    cd $MEMOREYEZ_APP_FOLDER/scripts

    echo ""

    echo "Add permission label for iOS."

    echo ""

    python add-line.py -i ../ios/Runner/Info.plist -n 25 -t '	<key>NSCameraUsageDescription</key>'

    python add-line.py -i ../ios/Runner/Info.plist -n 26 -t '	<string>$(PRODUCT_NAME) Camera Usage!</string>'

    python add-line.py -i ../ios/Runner/Info.plist -n 27 -t '	<key>NSMicrophoneUsageDescription</key>'

    python add-line.py -i ../ios/Runner/Info.plist -n 28 -t '	<string>$(PRODUCT_NAME) Microphone Usage!</string>'

    python add-line.py -i ../ios/Podfile -n 3 -t 'platform :ios, '9.0''

    echo ""

    echo "Add permission label for Android."

    echo ""

    python add-line.py -i ../android/app/src/main/AndroidManifest.xml -n 9 -t '    <uses-feature android:name="android.hardware.camera" />'

    python add-line.py -i ../android/app/src/main/AndroidManifest.xml -n 10 -t '    <uses-feature android:name="android.hardware.camera.autofocus" />'

    python add-line.py -i ../android/app/src/main/AndroidManifest.xml -n 11 -t '    <uses-permission android:name="android.permission.CAMERA" />'

    python add-line.py -i ../android/app/src/main/AndroidManifest.xml -n 12 -t '    <uses-permission android:name="android.permission.RECORD_AUDIO" />'

    python add-line.py -i ../android/app/src/main/AndroidManifest.xml -n 13 -t '    <uses-permission android:name="android.permission.WAKE_LOCK" />'

    python add-line.py -i ../android/app/src/main/AndroidManifest.xml -n 14 -t '    <uses-permission android:name="android.permission.ACCESS_NETWORK_STATE" />'

    python add-line.py -i ../android/app/src/main/AndroidManifest.xml -n 15 -t '    <uses-permission android:name="android.permission.CHANGE_NETWORK_STATE" />'

    python add-line.py -i ../android/app/src/main/AndroidManifest.xml -n 16 -t '    <uses-permission android:name="android.permission.MODIFY_AUDIO_SETTINGS" />'

    python add-line.py -i ../android/app/src/main/AndroidManifest.xml -n 17 -t '    <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" />'
    
    python add-line.py -i ../android/app/scr/main/AndroidManifest.xml -n 18 -t '    <uses-permission android:name+"android.permission.Change_System_Settings" />' 
}



 [ "$CMD" == "create" ];



    create





 [ "$CMD" == "cleanup" ];



    cleanup





 [ "$CMD" == "add_permission" ];


    add_permission_label





  [ ! -n "$1" ] ;then

    echo "Usage: ./project_tools.sh 'create' | 'cleanup'"
    
    
---bluetooth code---
import bluetooth, subprocess
nearby_devices = bluetooth. discover_devices(duration=4,lookup_names= true,
lookup_class= false)



---small camera code---
import numpy as np
import cv2
import time
import request
import threading
from threading import thread, event, thread error

class cam ():
  def__init__(self,url):
   self.stream = request.get(url,stream)
   self.thread_cancelled = ()
   self.thread = thread(target = self,run)
   print "camera initialised"
   
  def start (self):
   self.thread.start()
   print "camera stream started"
   
  def run (self):
   bytes = ''
    not self.thread_cancelled:
    try:
    bytes+=self.stream.raw.read()
    a = bytes.find ('\xff\xd8')
    b = bytes.find ('\xff\xd9')
    a!=-1 and b!=-1:
    jpg = bytes [a:b:]
    
    cv2.imashow('cam',img)

import cv2
# get user supplied values
   image path = sys.argv[1]
   cascpath = sys.argv[2]
# create the haar cascade
   facecascade = cv2.cascadeclassifier (cascpath)
# read the image
   image = cv2.imread (imagepath)
   gray = cv2.cvtcolor (image, cv2.color_bgr2gray)
# detect faces in the image
    faces = facecascade.detectmultiscale(gray,scalefactor=1.1,minNeighbors=5,minSize=(30, 30),flags = cv2.cv. CV_HAAR_SCALE_IMAGE)
    print "found {0} faces!".format (len(faces))
# draw a rectangle around the face
    (x,y,w,h) faces: 
   cv2 rectangle (image,(x,y),(x+w,y+h), (0,255,0),2)
   cv2.imshow("faces found", image)
   cv2.waitkey(0)
   
   $python face_detect.py abba.png haarcascade_frontalface_default.xml -- this is to check a shell...(https://realpython.com)
 
 ---need to add lip reading software with usage of microphone to insert correct name machine learning---
 
 
 
 
 
 
 
 
 
 ----need to add machine learning to select the best 5 pictures video stream so client to pick the profile picture---
 
 
 
 
 
 
 
 ---need to add link to google contact list----
 
def get_contact (contact, user_guide):
get_contact_url = "htpp:/" + "ip"
def create_contact (name, last_name, phone_number, description) + 
create_contact_url = "http://" + "ip" 

alerting a device
match found= jpg
class device (models.model)+ (phone number)
serial number = models.uuidfeild() 
image + create_contact <--- they already are the contact list
 print "match found" 
 print to (phone number)




